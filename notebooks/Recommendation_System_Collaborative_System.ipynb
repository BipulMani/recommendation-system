{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4IHIk92dg8v"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python' requires the ipykernel package.\n",
            "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
            "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Users/Anup/Desktop/Productivity/Project/recommendation-system/venv/Scripts/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from torch import nn, tensor, float32, save\n",
        "from torch.cuda import is_available\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "import pickle\n",
        "import joblib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyouy4m5h8Pq"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "movies_df = pd.read_csv('/content/movies.csv')\n",
        "ratings_df = pd.read_csv('/content/ratings.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxiPgOUPiuvk"
      },
      "outputs": [],
      "source": [
        "# Shape\n",
        "print(f\"Shape of movies dataframe: {movies_df.shape}\")\n",
        "print(f\"Shape of ratings dataframe: {ratings_df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zL6vDY_di4Qp"
      },
      "outputs": [],
      "source": [
        "movies_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMPCjyBVi6qx"
      },
      "outputs": [],
      "source": [
        "ratings_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhW5treei79R"
      },
      "outputs": [],
      "source": [
        "movie_names= movies_df.set_index('movieId')['title'].to_dict()\n",
        "n_users = len(ratings_df['userId'].unique())\n",
        "n_items = len(ratings_df['movieId'].unique())\n",
        "print(f\"Number of unique users: {n_users}\")\n",
        "print(f\"Number of unique movies: {n_items}\")\n",
        "print(f\"The full rating matrix will have: {n_users * n_items} elements\")\n",
        "print(f\"therefore {len(ratings_df) / (n_users * n_items) * 100}% of the matrix are filled.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1o5brE56Jon"
      },
      "outputs": [],
      "source": [
        "print(len(ratings_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJ6PG9MWkIVo"
      },
      "outputs": [],
      "source": [
        "class MatrixFactorization(nn.Module):\n",
        "\n",
        "  def __init__(self, n_users, n_items, n_factors=20):\n",
        "    super().__init__()\n",
        "\n",
        "    # Generate user embeddings\n",
        "    self.user_factors = nn.Embedding(n_users, n_factors)\n",
        "    self.item_factors = nn.Embedding(n_items, n_factors)\n",
        "\n",
        "    # Initialize the embeddings with continuous uniformly distributed values\n",
        "    self.user_factors.weight.data.uniform_(0, 0.05)\n",
        "    self.item_factors.weight.data.uniform_(0, 0.05)\n",
        "\n",
        "  def forward(self, data):\n",
        "    users, items = data[:,0], data[:,1]\n",
        "    return (self.user_factors(users) * self.item_factors(items)).sum(1)\n",
        "\n",
        "  def predict(self, user, item):\n",
        "    return self.forward(user, item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5R_D-pJlQq9"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class Loader(Dataset):\n",
        "  def __init__(self, ratings_df):\n",
        "\n",
        "    self.ratings_df = ratings_df.copy()\n",
        "\n",
        "    users = self.ratings_df['userId'].unique()\n",
        "    movies = self.ratings_df['movieId'].unique()\n",
        "\n",
        "    # Generate continuous IDs for users and movies\n",
        "\n",
        "    self.userIdToIdx = {o:i for i,o in enumerate(users)}\n",
        "    self.movieIdToIdx = {o:i for i,o in enumerate(movies)}\n",
        "\n",
        "    self.idxToUserId = {i:o for o,i in self.userIdToIdx.items()}\n",
        "    self.idxToMovieId = {i:o for o,i in self.movieIdToIdx.items()}\n",
        "\n",
        "    self.ratings_df['movieId'] = ratings_df['movieId'].apply(lambda x: self.movieIdToIdx[x])\n",
        "    self.ratings_df['userId'] = ratings_df['userId'].apply(lambda x: self.userIdToIdx[x])\n",
        "\n",
        "    self.x = self.ratings_df.drop(['rating', 'timestamp'], axis=1).values\n",
        "    self.y = self.ratings_df['rating'].values\n",
        "    self.x, self.y = tensor(self.x), tensor(self.y)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return (self.x[index], self.y[index])\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.ratings_df.shape[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNGOcmaFmpqq"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 128\n",
        "LEARNING_RATE = 1e-3\n",
        "BATCH_SIZE = 128\n",
        "DEVICE = \"cuda\" if is_available() else \"cpu\"\n",
        "\n",
        "model = MatrixFactorization(n_users=n_users, n_items=n_items, n_factors=8)\n",
        "\n",
        "print(f\"Device: {DEVICE}\")\n",
        "print(f\"Model: {model}\")\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "  if param.requires_grad:\n",
        "    print(name, param.data)\n",
        "\n",
        "if DEVICE == \"cuda\":\n",
        "  model.cuda()\n",
        "else:\n",
        "  model.cpu()\n",
        "\n",
        "# Loss function\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# DataLoader\n",
        "train_set = Loader(ratings_df=ratings_df)\n",
        "train_loader = DataLoader(train_set, BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8eH1MYXph_0"
      },
      "outputs": [],
      "source": [
        "for iter in tqdm(range(NUM_EPOCHS)):\n",
        "  total_loss = []\n",
        "  for x, y in train_loader:\n",
        "    if DEVICE == \"cuda\":\n",
        "      x, y = x.cuda(), y.cuda()\n",
        "    else:\n",
        "      x, y = x.cpu(), y.cpu()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(x)\n",
        "    loss = loss_fn(outputs.squeeze(), y.type(float32))\n",
        "    total_loss.append(loss.item())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  if iter % 10 == 0:\n",
        "    print(f\"Iteration: {iter}, Loss: {sum(total_loss)/len(total_loss)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADEm3dMz80Ex"
      },
      "outputs": [],
      "source": [
        "print(f\"Loss: {sum(total_loss)/len(total_loss)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJvwhoII-JMf"
      },
      "outputs": [],
      "source": [
        "# Latent factors for movies and users\n",
        "c = 0\n",
        "uw = 0\n",
        "iw = 0\n",
        "for name, param in model.named_parameters():\n",
        "  if param.requires_grad:\n",
        "    print(name, param.data)\n",
        "    if c == 0:\n",
        "      uw = param.data\n",
        "      c += 1\n",
        "    else:\n",
        "      iw = param.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klPsmGHc-efX"
      },
      "outputs": [],
      "source": [
        "trained_movie_embeddings = model.item_factors.weight.data.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nX8x7wwV-nXO"
      },
      "outputs": [],
      "source": [
        "len(trained_movie_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tt1SD0F2-p6m"
      },
      "outputs": [],
      "source": [
        "kMeans = KMeans(n_clusters=10, random_state=0).fit(trained_movie_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzUJBDvH--nd"
      },
      "outputs": [],
      "source": [
        "for cluster in range(10):\n",
        "  print(f\"Cluster #{cluster}\")\n",
        "  cluster_movies = []\n",
        "  # Find indices of the movies\n",
        "  for movieIdx in np.where(kMeans.labels_ == cluster)[0]:\n",
        "    movieId = train_set.idxToMovieId[movieIdx]\n",
        "    # Check the ratings of the movie\n",
        "    rat_count = len(ratings_df.loc[ratings_df['movieId']==movieId])\n",
        "    cluster_movies.append((movie_names[movieId], rat_count))\n",
        "  # Sort movies by rating count\n",
        "  for movie in sorted(cluster_movies, key=lambda tup: tup[1], reverse=True)[:10]:\n",
        "    print(\"\\t\", movie[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqRdMKmIAa6k"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdZA8YcYAwET"
      },
      "outputs": [],
      "source": [
        "# Save model\n",
        "save(model.state_dict(), \"matrix_factorization.pt\")\n",
        "\n",
        "# Save mappings\n",
        "mappings = {\n",
        "    \"userIdToIdx\": train_set.userIdToIdx,\n",
        "    \"movieIdToIdx\": train_set.movieIdToIdx,\n",
        "    \"idxToUserId\": train_set.idxToUserId,\n",
        "    \"idxToMovieId\": train_set.idxToMovieId,\n",
        "}\n",
        "\n",
        "with open(\"mappings.pkl\", \"wb\") as f:\n",
        "    pickle.dump(mappings, f)\n",
        "    f.close()\n",
        "\n",
        "# Save kMeans\n",
        "joblib.dump(kMeans, \"kmeans_model.pkl\")\n",
        "\n",
        "# Save trained movie embeddings\n",
        "trained_movie_embeddings = model.item_factors.weight.data.cpu().numpy()\n",
        "np.save(\"movie_embeddings.npy\", trained_movie_embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-auJxMsCgmp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
